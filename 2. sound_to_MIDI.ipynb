{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try of getting an Amplitude vs Time Graph.\n",
    "\n",
    "While this does achieve a graph, I was mainly just trying to understand the terms and functions of how to deal with the graph, hence heavy the commenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import pathlib #find directory of a folder so that it works for other OSs\n",
    "###import os #read the contents within folder\n",
    "###------------### Only necessary when we do the searching for melody directory.\n",
    "\n",
    "\n",
    "import pygame #start and stop of track playing\n",
    "import scipy #has the fft <-- see OneNote page for explanation\n",
    "#https://realpython.com/python-scipy-fft/\n",
    "#http://www.differencebetween.net/technology/difference-between-fft-and-dft/\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "audio_to_identify = \"C:\\$$$AUDIO FILES\\C3.wav\"\n",
    "rate, data = wavfile.read(audio_to_identify)\n",
    "#mmap = False <-- file is not too large that it has to be mapped\n",
    "# like any file, we have to read the information inside of it to do stuff with it.\n",
    "\n",
    "\n",
    "#print(rate) #define rate: https://www.adobe.com/uk/creativecloud/video/discover/audio-sampling.html\n",
    "#print(data) #define data: https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "#data == the shape of the wave\n",
    "\n",
    "##GETTING TO KNOW THE FUNCTIONS OF SCIPY TO DO WITH WAV\n",
    "print(f\"number of channels = {data.shape[1]}\")\n",
    "length = data.shape[0] / rate #whole entire audio file/ the frequency of wave\n",
    "print(f\"length = {length}s\")\n",
    "print(data.shape[0])\n",
    "\n",
    "##PLOTTING THE WAVE!!! -- Amplitude vs Time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "time = np.linspace(0., length, data.shape[0])\n",
    "plt.plot(time, data[:, 0], label=\"Left channel\")\n",
    "plt.plot(time, data[:, 1], label=\"Right channel\") #which speaker sound coming out of\n",
    "plt.legend() #where the key for the graph is\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALISATION -- important so sound can actually be heard. If amplitude/ power (power is the official term in programming for sound, but I use power and amplitude interchangeably as it means the same thing) is too small, then the tone will be harder to distinguish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NORMALISATION\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "in_wav = \"C:\\$$$AUDIO FILES\\$$FULL_c3_major_scale.wav\"\n",
    "rate, data = wavfile.read(in_wav) \n",
    "##rate = data points per second\n",
    "normalised_tone = np.int16((data[:,0]/data[:,0].max()) * 32767)\n",
    "# this is the tone definition normalizes to 32k bits = standard height for the tone to be identified\n",
    "#32767 = 2^15 - 1, thus putting the .WAV file into the standard 16-bit height\n",
    "#[:,0] is to get the data for one channel (speaker) because both channels will have similar data\n",
    "#so it does not make sense to have data from both channels.\n",
    "plt.plot(normalised_tone)\n",
    "plt.xlabel(\"Point in Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.ylim([-32767, 32767])\n",
    "plt.show()\n",
    "#Normalized tone will be used for further analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING LIST OF ALL NOTES ON PIANO\n",
    "\n",
    "Realistically, especially because the aim is to take human pitch and turn that into MIDI, the possible notes a human can reach are all going to be on a piano, and even then this is a very generous range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\$$$AUDIO FILES\\TO_USE-Note_To_MIDI_Table.csv\") as f:\n",
    "    formatted_all_notes = []\n",
    "    all_notes = [line.split() for line in f]\n",
    "    for lst in all_notes[1:]:\n",
    "        for elem in lst:\n",
    "            elem = elem.split(\",\")\n",
    "            for i in range (1,4):\n",
    "                if i == 1 or i == 3:\n",
    "                    elem[i] = int(elem[i])\n",
    "                else:\n",
    "                    elem[i] = float(elem[i])\n",
    "            formatted_all_notes.append(elem)\n",
    "print(formatted_all_notes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST FORAY INTO RFFT\n",
    "\n",
    "This is just a short note for why rfft is used in this code. For explanation of what it does (i.e. what is Fourier Transformation), please see OneNote.\n",
    "\n",
    "rfft is used because:\n",
    "(a) fft itself is quicker than dft\n",
    "(b) rfft only takes values above zero -- sound is a sine curve so both positive and negative values are included\n",
    "but in this case, not necessary because it is just a mirror image so dealing with positive numbers is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq #new!!!\n",
    "\n",
    "in_wav = \"C:\\$$$AUDIO FILES\\C3.wav\"\n",
    "rate, data = wavfile.read(in_wav) \n",
    "normalised_tone = np.int16((data[:,0]/data[:,0].max()) * 32767)\n",
    "plt.plot(normalised_tone)\n",
    "plt.xlabel(\"Point in Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.ylim([-32767, 32767])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------ #\n",
    "yf = rfft(normalised_tone) #calculates the transform itself\n",
    "xf = rfftfreq(len(normalised_tone), 1 / rate) #calculates the frequencies in centre of each bin in output of fft\n",
    "\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING ONE TONE FROM WHOLE FILE -- PIANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BERKES~1\\AppData\\Local\\Temp/ipykernel_988/8183164.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mlengthofwavinseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mlengthofwavindatapoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mnormalised_tone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m32767\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m### STEP 2: HOW TO GET TONE OF WHOLE FILE -- ONLY FOR ONE PITCH FILE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "in_wav = \"C:\\$$$AUDIO FILES\\VOICE_C3.wav\"\n",
    "\n",
    "### STEP ONE: GET RID OF ONE CHANNEL IF ORIGINAL RECORDING HAS TWO SO EASIER TO DEAL WITH + NORMALISE FILE \n",
    "rate, data = wavfile.read(in_wav)\n",
    "normalised_tone = np.int16((data[:,0]/data[:,0].max()) * 32767)\n",
    "\n",
    "### STEP 2: HOW TO GET TONE OF WHOLE FILE -- ONLY FOR ONE PITCH FILE\n",
    "\n",
    "def single_pitch_to_MIDI(normalised_tone,rate):\n",
    "    yf = rfft(normalised_tone) \n",
    "    xf = rfftfreq(len(normalised_tone),1/rate) \n",
    "\n",
    "    points_per_freq = len(xf) / (rate/2)\n",
    "    # This is the number of points plotted per 1Hz of frequency.\n",
    "    # The maximum frequency possibly reached is half the sample rate\n",
    "    to_cut_off = int(points_per_freq * 4200) # Sets up point to cut sound off at 4200Hz because piano's highest key is 4186Hz\n",
    "\n",
    "    yf = yf[:to_cut_off+1] # Cut off all points above 4200 Hz\n",
    "    xf = xf[:to_cut_off+1]\n",
    "\n",
    "\n",
    "\n",
    "    A = 0\n",
    "    Amax = 0\n",
    "    possible_tones = [['A0', 21, 27.5, 0], ['As0/Bb0', 22, 29.14, 0], ['B0', 23, 30.87, 0], ['C1', 24, 32.7, 0], ['Cs1/Db1', 25, 34.65, 0], ['D1', 26, 36.71, 0], ['Ds1/Eb1', 27, 38.89, 0], ['E1', 28, 41.2, 0], ['F1', 29, 43.65, 0], ['Fs1/Gb1', 30, 46.25, 0], ['G1', 31, 49.0, 0], ['Gs1/Ab1', 32, 51.91, 0], ['A1', 33, 55.0, 0], ['As1/Bb1', 34, 58.27, 0], ['B1', 35, 61.74, 0], ['C2', 36, 65.41, 0], ['Cs1/Db2', 37, 69.3, 0], ['D2', 38, 73.42, 0], ['Ds1/Eb2', 39, 77.78, 0], ['E2', 40, 82.41, 0], ['F2', 41, 87.31, 0], ['Fs1/Gb2', 42, 92.5, 0], ['G2', 43, 98.0, 0], ['Gs1/Ab2', 44, 103.83, 0], ['A2', 45, 110.0, 0], ['As1/Bb2', 46, 116.54, 0], ['B2', 47, 123.47, 0], ['C3', 48, 130.81, 0], ['Cs1/Db3', 49, 138.59, 0], ['D3', 50, 146.83, 0], ['Ds1/Eb3', 51, 155.56, 0], ['E3', 52, 164.81, 0], ['F3', 53, 174.61, 0], ['Fs1/Gb3', 54, 185.0, 0], ['G3', 55, 196.0, 0], ['Gs1/Ab3', 56, 207.65, 0], ['A3', 57, 220.0, 0], ['As1/Bb3', 58, 233.08, 0], ['B3', 59, 246.94, 0], ['C4', 60, 261.63, 0], ['Cs1/Db4', 61, 277.18, 0], ['D4', 62, 293.66, 0], ['Ds1/Eb4', 63, 311.13, 0], ['E4', 64, 329.63, 0], ['F4', 65, 349.23, 0], ['Fs1/Gb4', 66, 369.99, 0], ['G4', 67, 392.0, 0], ['Gs1/Ab4', 68, 415.3, 0], ['A4', 69, 440.0, 0], ['As1/Bb4', 70, 466.16, 0], ['B4', 71, 493.88, 0], ['C5', 72, 523.25, 0], ['Cs1/Db5', 73, 554.37, 0], ['D5', 74, 587.33, 0], ['Ds1/Eb5', 75, 622.25, 0], ['E5', 76, 659.26, 0], ['F5', 77, 698.46, 0], ['Fs1/Gb5', 78, 739.99, 0], ['G5', 79, 783.99, 0], ['Gs1/Ab5', 80, 830.61, 0], ['A5', 81, 880.0, 0], ['As1/Bb5', 82, 932.33, 0], ['B5', 83, 987.77, 0], ['C6', 84, 1046.5, 0], ['Cs1/Db6', 85, 1108.73, 0], ['D6', 86, 1174.66, 0], ['Ds1/Eb6', 87, 1244.51, 0], ['E6', 88, 1318.51, 0], ['F6', 89, 1396.91, 0], ['Fs1/Gb6', 90, 1479.98, 0], ['G6', 91, 1567.98, 0], ['Gs1/Ab6', 92, 1661.22, 0], ['A6', 93, 1760.0, 0], ['As1/Bb6', 94, 1864.66, 0], ['B6', 95, 1975.53, 0], ['C7', 96, 2093.0, 0], ['Cs1/Db7', 97, 2217.46, 0], ['D7', 98, 2349.32, 0], ['Ds1/Eb7', 99, 2489.02, 0], ['E7', 100, 2637.02, 0], ['F7', 101, 2793.83, 0], ['Fs1/Gb7', 102, 2959.96, 0], ['G7', 103, 3135.96, 0], ['Gs1/Ab7', 104, 3322.44, 0], ['A7', 105, 3520.0, 0], ['As1/Bb7', 106, 3729.31, 0], ['B7', 107, 3951.07, 0], ['C8', 108, 4186.01, 0]]\n",
    "    # This is a VERY long list of all notes on Piano. While yes, I could have kept this in a .csv file or even put this into a dictionary,\n",
    "    # I wanted to have it clearly written in front of me.\n",
    "    # This also makes it easier to edit and/or change the list as necessary.\n",
    "    # FORMAT OF LIST: [note, MIDI, frequency, amplitude]\n",
    "    # Amplitude will change depending on what will be read from the .WAV file.\n",
    "\n",
    "\n",
    "    for i in range(0,len(possible_tones)):\n",
    "        f = possible_tones[i][2]\n",
    "        # This is the frequency of the tone in the table.\n",
    "        # Even though the sound from the file may not reach this perfect frequency, each MIDI's frequency is perfect, so\n",
    "        # analysis of the sound needs to be done to find the most prominent perfect frequency.\n",
    "        for j in range(to_cut_off-1):\n",
    "            f1 = xf[j] #point on graph x-axis to analyse\n",
    "            f2 = xf[j+1] #one ahead of point f1\n",
    "            if  (f1 <= f < f2):\n",
    "                A = abs(abs(yf[j+1]) - abs(yf[j]))/(f2-f1)+abs(yf[j])\n",
    "                if A > Amax:\n",
    "                    Amax = A\n",
    "                    jmax = i\n",
    "                possible_tones[i][3] = A\n",
    "                break    \n",
    "    # Method behind this:\n",
    "    # \n",
    "    # See OneNote for more in-depth description\n",
    "#------------------------------------------------------------------------------------\n",
    "    \n",
    "    p = len(possible_tones)\n",
    "    for pp in range(len(possible_tones)):\n",
    "        if Amax != 0:\n",
    "            possible_tones[pp][3] = possible_tones[pp][3]/Amax*100\n",
    "            if possible_tones[pp][3] <=10:\n",
    "                # Tones less than 10 power/ amplitude are filtered out -- tone set to 1 as negligible sound.\n",
    "                possible_tones[pp][3] = 1\n",
    "        else:\n",
    "            possible_tones[pp][3] = 1\n",
    "\n",
    "\n",
    "\n",
    "##INSTRUMENT ROUTINE\n",
    "    for tn in possible_tones:\n",
    "        if tn[3] > 1: #finds the first tone with volume above 10\n",
    "            maxko = tn[0]\n",
    "            m = tn[1]\n",
    "            maxvol = tn[3]\n",
    "            break\n",
    "    \n",
    "##    print(\"m strategy first above 10 tone: \",m,maxvol)\n",
    "##    input()\n",
    "###HUMAN VOICE  ROUTINE\n",
    "    # if tonestype == \"human\":\n",
    "    # m = possible_tones[jmax][1] #this is max volume tone in the sample - good for HUMAN voice identification - not for instrument\n",
    "    # maxvol = possible_tones[jmax][3]\n",
    "\n",
    "    for elem in possible_tones:\n",
    "        print(elem)\n",
    "    return m\n",
    "#####FUNCTION WHICH RETURNS SINGLE MIDI FOR SINGLE TONE FILE - END\n",
    "\n",
    "single_pitch_to_MIDI(normalised_tone,rate)\n",
    "\n",
    "# ####FUNCTION FOR RETURNING WRITTEN TONE FROM MIDI VALUE\n",
    "# def findthetonetomidi(midivalue):\n",
    "#     tone=[['A0', 'A', 0, 27.5, 21, 0], ['Bb0', 'Bb', 0, 29.135, 22, 0], ['B0', 'B', 0, 30.868, 23, 0], ['C1', 'C', 1, 32.703, 24, 0], ['Cs1', 'Cs', 1, 34.648, 25, 0], ['D1', 'D', 1, 36.708, 26, 0], ['Eb1', 'Eb', 1, 38.891, 27, 0], ['E1', 'E', 1, 41.203, 28, 0], ['F1', 'F', 1, 43.654, 29, 0], ['Fs1', 'Fs', 1, 46.249, 30, 0], ['G1', 'G', 1, 48.999, 31, 0], ['Gs1', 'Gs', 1, 51.913, 32, 0], ['A1', 'A', 1, 55, 33, 0], ['Bb1', 'Bb', 1, 58.27, 34, 0], ['B1', 'B', 1, 61.735, 35, 0], ['C2', 'C', 2, 65.406, 36, 0], ['Cs2', 'Cs', 2, 69.296, 37, 0], ['D2', 'D', 2, 73.416, 38, 0], ['Eb2', 'Eb', 2, 77.782, 39, 0], ['E2', 'E', 2, 82.407, 40, 0], ['F2', 'F', 2, 87.307, 41, 0], ['Fs2', 'Fs', 2, 92.499, 42, 0], ['G2', 'G', 2, 97.999, 43, 0], ['Gs2', 'Gs', 2, 103.83, 44, 0], ['A2', 'A', 2, 110, 45, 0], ['Bb2', 'Bb', 2, 116.54, 46, 0], ['B2', 'B', 2, 123.47, 47, 0], ['C3', 'C', 3, 130.81, 48, 0], ['Cs3', 'Cs', 3, 138.59, 49, 0], ['D3', 'D', 3, 146.83, 50, 0], ['Eb3', 'Eb', 3, 155.56, 51, 0], ['E3', 'E', 3, 164.81, 52, 0], ['F3', 'F', 3, 174.61, 53, 0], ['Fs3', 'Fs', 3, 185, 54, 0], ['G3', 'G', 3, 196, 55, 0], ['Gs3', 'Gs', 3, 207.65, 56, 0], ['A3', 'A', 3, 220, 57, 0], ['Bb3', 'Bb', 3, 233.08, 58, 0], ['B3', 'B', 3, 246.94, 59, 0], ['C4', 'C', 4, 261.63, 60, 0], ['Cs4', 'Cs', 4, 277.18, 61, 0], ['D4', 'D', 4, 293.66, 62, 0], ['Eb4', 'Eb', 4, 311.13, 63, 0], ['E4', 'E', 4, 329.63, 64, 0], ['F4', 'F', 4, 349.23, 65, 0], ['Fs4', 'Fs', 4, 369.99, 66, 0], ['G4', 'G', 4, 392, 67, 0], ['Gs4', 'Gs', 4, 415.3, 68, 0], ['A4', 'A', 4, 440, 69, 0], ['Bb4', 'Bb', 4, 466.16, 70, 0], ['B4', 'B', 4, 493.88, 71, 0], ['C5', 'C', 5, 523.25, 72, 0], ['Cs5', 'Cs', 5, 554.37, 73, 0], ['D5', 'D', 5, 587.33, 74, 0], ['Eb5', 'Eb', 5, 622.25, 75, 0], ['E5', 'E', 5, 659.26, 76, 0], ['F5', 'F', 5, 698.46, 77, 0], ['Fs5', 'Fs', 5, 739.99, 78, 0], ['G5', 'G', 5, 783.99, 79, 0], ['Gs5', 'Gs', 5, 830.61, 80, 0], ['A5', 'A', 5, 880, 81, 0], ['Bb5', 'Bb', 5, 932.33, 82, 0], ['B5', 'B', 5, 987.77, 83, 0], ['C6', 'C', 6, 1046.5, 84, 0], ['Cs6', 'Cs', 6, 1108.73, 85, 0], ['D6', 'D', 6, 1174.66, 86, 0], ['Eb6', 'Eb', 6, 1244.51, 87, 0], ['E6', 'E', 6, 1318.51, 88, 0], ['F6', 'F', 6, 1396.91, 89, 0], ['Fs6', 'Fs', 6, 1479.98, 90, 0], ['G6', 'G', 6, 1567.98, 91, 0], ['Gs6', 'Gs', 6, 1661.22, 92, 0], ['A6', 'A', 6, 1760, 93, 0], ['Bb6', 'Bb', 6, 1864.66, 94, 0], ['B6', 'B', 6, 1975.53, 95, 0], ['C7', 'C', 7, 2093, 96, 0], ['Cs7', 'Cs', 7, 2217.46, 97, 0], ['D7', 'D', 7, 2349.32, 98, 0], ['Eb7', 'Eb', 7, 2489.02, 99, 0], ['E7', 'E', 7, 2637.02, 100, 0], ['F7', 'F', 7, 2793.83, 101, 0], ['Fs7', 'Fs', 7, 2959.96, 102, 0], ['G7', 'G', 7, 3135.96, 103, 0], ['Gs7', 'Gs', 7, 3322.44, 104, 0], ['A7', 'A', 7, 3520, 105, 0], ['Bb7', 'Bb', 7, 3729.31, 106, 0], ['B7', 'B', 7, 3951.07, 107, 0], ['C8', 'C', 8, 4186.01, 108, 0]]\n",
    "#     miditone=0\n",
    "#     for t in range(0,len(tone)):\n",
    "#             if tone[t][4] == midivalue:\n",
    "#                 miditone = tone[t][0]\n",
    "#                 break\n",
    "#     return(miditone)\n",
    "# ####FUNCTION FOR RETURNING TONE FROM MIDI VALUE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING TONE FROM ONE FILE -- HUMAN VOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0', 21, 27.5, 1]\n",
      "['As0/Bb0', 22, 29.14, 1]\n",
      "['B0', 23, 30.87, 1]\n",
      "['C1', 24, 32.7, 1]\n",
      "['Cs1/Db1', 25, 34.65, 1]\n",
      "['D1', 26, 36.71, 1]\n",
      "['Ds1/Eb1', 27, 38.89, 1]\n",
      "['E1', 28, 41.2, 1]\n",
      "['F1', 29, 43.65, 1]\n",
      "['Fs1/Gb1', 30, 46.25, 1]\n",
      "['G1', 31, 49.0, 1]\n",
      "['Gs1/Ab1', 32, 51.91, 1]\n",
      "['A1', 33, 55.0, 1]\n",
      "['As1/Bb1', 34, 58.27, 1]\n",
      "['B1', 35, 61.74, 1]\n",
      "['C2', 36, 65.41, 1]\n",
      "['Cs1/Db2', 37, 69.3, 1]\n",
      "['D2', 38, 73.42, 1]\n",
      "['Ds1/Eb2', 39, 77.78, 1]\n",
      "['E2', 40, 82.41, 1]\n",
      "['F2', 41, 87.31, 1]\n",
      "['Fs1/Gb2', 42, 92.5, 1]\n",
      "['G2', 43, 98.0, 1]\n",
      "['Gs1/Ab2', 44, 103.83, 1]\n",
      "['A2', 45, 110.0, 1]\n",
      "['As1/Bb2', 46, 116.54, 1]\n",
      "['B2', 47, 123.47, 1]\n",
      "['C3', 48, 130.81, 1]\n",
      "['Cs1/Db3', 49, 138.59, 1]\n",
      "['D3', 50, 146.83, 1]\n",
      "['Ds1/Eb3', 51, 155.56, 1]\n",
      "['E3', 52, 164.81, 1]\n",
      "['F3', 53, 174.61, 1]\n",
      "['Fs1/Gb3', 54, 185.0, 1]\n",
      "['G3', 55, 196.0, 1]\n",
      "['Gs1/Ab3', 56, 207.65, 1]\n",
      "['A3', 57, 220.0, 1]\n",
      "['As1/Bb3', 58, 233.08, 1]\n",
      "['B3', 59, 246.94, 1]\n",
      "['C4', 60, 261.63, 100.0]\n",
      "['Cs1/Db4', 61, 277.18, 1]\n",
      "['D4', 62, 293.66, 1]\n",
      "['Ds1/Eb4', 63, 311.13, 1]\n",
      "['E4', 64, 329.63, 1]\n",
      "['F4', 65, 349.23, 1]\n",
      "['Fs1/Gb4', 66, 369.99, 1]\n",
      "['G4', 67, 392.0, 1]\n",
      "['Gs1/Ab4', 68, 415.3, 1]\n",
      "['A4', 69, 440.0, 1]\n",
      "['As1/Bb4', 70, 466.16, 1]\n",
      "['B4', 71, 493.88, 1]\n",
      "['C5', 72, 523.25, 10.39717523418738]\n",
      "['Cs1/Db5', 73, 554.37, 1]\n",
      "['D5', 74, 587.33, 1]\n",
      "['Ds1/Eb5', 75, 622.25, 1]\n",
      "['E5', 76, 659.26, 1]\n",
      "['F5', 77, 698.46, 1]\n",
      "['Fs1/Gb5', 78, 739.99, 1]\n",
      "['G5', 79, 783.99, 19.8908613182775]\n",
      "['Gs1/Ab5', 80, 830.61, 1]\n",
      "['A5', 81, 880.0, 1]\n",
      "['As1/Bb5', 82, 932.33, 1]\n",
      "['B5', 83, 987.77, 1]\n",
      "['C6', 84, 1046.5, 1]\n",
      "['Cs1/Db6', 85, 1108.73, 1]\n",
      "['D6', 86, 1174.66, 1]\n",
      "['Ds1/Eb6', 87, 1244.51, 1]\n",
      "['E6', 88, 1318.51, 1]\n",
      "['F6', 89, 1396.91, 1]\n",
      "['Fs1/Gb6', 90, 1479.98, 1]\n",
      "['G6', 91, 1567.98, 1]\n",
      "['Gs1/Ab6', 92, 1661.22, 1]\n",
      "['A6', 93, 1760.0, 1]\n",
      "['As1/Bb6', 94, 1864.66, 1]\n",
      "['B6', 95, 1975.53, 1]\n",
      "['C7', 96, 2093.0, 1]\n",
      "['Cs1/Db7', 97, 2217.46, 1]\n",
      "['D7', 98, 2349.32, 1]\n",
      "['Ds1/Eb7', 99, 2489.02, 1]\n",
      "['E7', 100, 2637.02, 1]\n",
      "['F7', 101, 2793.83, 1]\n",
      "['Fs1/Gb7', 102, 2959.96, 1]\n",
      "['G7', 103, 3135.96, 1]\n",
      "['Gs1/Ab7', 104, 3322.44, 1]\n",
      "['A7', 105, 3520.0, 1]\n",
      "['As1/Bb7', 106, 3729.31, 1]\n",
      "['B7', 107, 3951.07, 1]\n",
      "['C8', 108, 4186.01, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "in_wav = \"C:\\$$$AUDIO FILES\\VOICE_C3.wav\"\n",
    "\n",
    "### STEP ONE: GET RID OF ONE CHANNEL IF ORIGINAL RECORDING HAS TWO SO EASIER TO DEAL WITH + NORMALISE FILE \n",
    "rate, data = wavfile.read(in_wav)\n",
    "if data.ndim == 2: #data.ndim returns whether 1D or 2D list, i.e. 1 channel or 2 channels\n",
    "    normalised_tone = np.int16((data[:,0]/data[:,0].max()) * 32767)\n",
    "else:\n",
    "    normalised_tone = np.int16((data[:]/data[:].max()) * 32767)\n",
    "\n",
    "### STEP 2: HOW TO GET TONE OF WHOLE FILE -- ONLY FOR ONE PITCH FILE\n",
    "\n",
    "def single_pitch_to_MIDI(normalised_tone,rate):\n",
    "    yf = rfft(normalised_tone) \n",
    "    xf = rfftfreq(len(normalised_tone),1/rate) \n",
    "\n",
    "    points_per_freq = len(xf) / (rate/2)\n",
    "    # This is the number of points plotted per 1Hz of frequency.\n",
    "    # The maximum frequency possibly reached is half the sample rate\n",
    "    to_cut_off = int(points_per_freq * 4200) # Sets up point to cut sound off at 4200Hz because piano's highest key is 4186Hz\n",
    "\n",
    "    yf = yf[:to_cut_off+1] # Cut off all points above 4200 Hz\n",
    "    xf = xf[:to_cut_off+1]\n",
    "\n",
    "\n",
    "\n",
    "    A = 0\n",
    "    Amax = 0\n",
    "    possible_tones = [['A0', 21, 27.5, 0], ['As0/Bb0', 22, 29.14, 0], ['B0', 23, 30.87, 0], ['C1', 24, 32.7, 0], ['Cs1/Db1', 25, 34.65, 0], ['D1', 26, 36.71, 0], ['Ds1/Eb1', 27, 38.89, 0], ['E1', 28, 41.2, 0], ['F1', 29, 43.65, 0], ['Fs1/Gb1', 30, 46.25, 0], ['G1', 31, 49.0, 0], ['Gs1/Ab1', 32, 51.91, 0], ['A1', 33, 55.0, 0], ['As1/Bb1', 34, 58.27, 0], ['B1', 35, 61.74, 0], ['C2', 36, 65.41, 0], ['Cs1/Db2', 37, 69.3, 0], ['D2', 38, 73.42, 0], ['Ds1/Eb2', 39, 77.78, 0], ['E2', 40, 82.41, 0], ['F2', 41, 87.31, 0], ['Fs1/Gb2', 42, 92.5, 0], ['G2', 43, 98.0, 0], ['Gs1/Ab2', 44, 103.83, 0], ['A2', 45, 110.0, 0], ['As1/Bb2', 46, 116.54, 0], ['B2', 47, 123.47, 0], ['C3', 48, 130.81, 0], ['Cs1/Db3', 49, 138.59, 0], ['D3', 50, 146.83, 0], ['Ds1/Eb3', 51, 155.56, 0], ['E3', 52, 164.81, 0], ['F3', 53, 174.61, 0], ['Fs1/Gb3', 54, 185.0, 0], ['G3', 55, 196.0, 0], ['Gs1/Ab3', 56, 207.65, 0], ['A3', 57, 220.0, 0], ['As1/Bb3', 58, 233.08, 0], ['B3', 59, 246.94, 0], ['C4', 60, 261.63, 0], ['Cs1/Db4', 61, 277.18, 0], ['D4', 62, 293.66, 0], ['Ds1/Eb4', 63, 311.13, 0], ['E4', 64, 329.63, 0], ['F4', 65, 349.23, 0], ['Fs1/Gb4', 66, 369.99, 0], ['G4', 67, 392.0, 0], ['Gs1/Ab4', 68, 415.3, 0], ['A4', 69, 440.0, 0], ['As1/Bb4', 70, 466.16, 0], ['B4', 71, 493.88, 0], ['C5', 72, 523.25, 0], ['Cs1/Db5', 73, 554.37, 0], ['D5', 74, 587.33, 0], ['Ds1/Eb5', 75, 622.25, 0], ['E5', 76, 659.26, 0], ['F5', 77, 698.46, 0], ['Fs1/Gb5', 78, 739.99, 0], ['G5', 79, 783.99, 0], ['Gs1/Ab5', 80, 830.61, 0], ['A5', 81, 880.0, 0], ['As1/Bb5', 82, 932.33, 0], ['B5', 83, 987.77, 0], ['C6', 84, 1046.5, 0], ['Cs1/Db6', 85, 1108.73, 0], ['D6', 86, 1174.66, 0], ['Ds1/Eb6', 87, 1244.51, 0], ['E6', 88, 1318.51, 0], ['F6', 89, 1396.91, 0], ['Fs1/Gb6', 90, 1479.98, 0], ['G6', 91, 1567.98, 0], ['Gs1/Ab6', 92, 1661.22, 0], ['A6', 93, 1760.0, 0], ['As1/Bb6', 94, 1864.66, 0], ['B6', 95, 1975.53, 0], ['C7', 96, 2093.0, 0], ['Cs1/Db7', 97, 2217.46, 0], ['D7', 98, 2349.32, 0], ['Ds1/Eb7', 99, 2489.02, 0], ['E7', 100, 2637.02, 0], ['F7', 101, 2793.83, 0], ['Fs1/Gb7', 102, 2959.96, 0], ['G7', 103, 3135.96, 0], ['Gs1/Ab7', 104, 3322.44, 0], ['A7', 105, 3520.0, 0], ['As1/Bb7', 106, 3729.31, 0], ['B7', 107, 3951.07, 0], ['C8', 108, 4186.01, 0]]\n",
    "    # This is a VERY long list of all notes on Piano. While yes, I could have kept this in a .csv file or even put this into a dictionary,\n",
    "    # I wanted to have it clearly written in front of me.\n",
    "    # This also makes it easier to edit and/or change the list as necessary.\n",
    "    # FORMAT OF LIST: [note, MIDI, frequency, amplitude]\n",
    "    # Amplitude will change depending on what will be read from the .WAV file.\n",
    "\n",
    "\n",
    "    for i in range(0,len(possible_tones)):\n",
    "        f = possible_tones[i][2]\n",
    "        # This is the frequency of the tone in the table.\n",
    "        # Even though the sound from the file may not reach this perfect frequency, each MIDI's frequency is perfect, so\n",
    "        # analysis of the sound needs to be done to find the most prominent perfect frequency.\n",
    "        for j in range(to_cut_off-1):\n",
    "            f1 = xf[j] #point on graph x-axis to analyse\n",
    "            f2 = xf[j+1] #one ahead of point f1\n",
    "            if  (f1 <= f < f2):\n",
    "                A = abs(abs(yf[j+1]) - abs(yf[j]))/(f2-f1)+abs(yf[j])\n",
    "                if A > Amax:\n",
    "                    Amax = A\n",
    "                    jmax = i\n",
    "                possible_tones[i][3] = A\n",
    "                break    \n",
    "    # Method behind this:\n",
    "    # \n",
    "    # See OneNote for more in-depth description\n",
    "#------------------------------------------------------------------------------------\n",
    "    \n",
    "    p = len(possible_tones)\n",
    "    for pp in range(len(possible_tones)):\n",
    "        if Amax != 0:\n",
    "            possible_tones[pp][3] = possible_tones[pp][3]/Amax*100\n",
    "            if possible_tones[pp][3] <=10:\n",
    "                # Tones less than 10 power/ amplitude are filtered out -- tone set to 1 as negligible sound.\n",
    "                possible_tones[pp][3] = 1\n",
    "        else:\n",
    "            possible_tones[pp][3] = 1\n",
    "\n",
    "\n",
    "\n",
    "##INSTRUMENT ROUTINE\n",
    "    for tn in possible_tones:\n",
    "        if tn[3] > 1: #finds the first tone with volume above 10\n",
    "            maxko = tn[0]\n",
    "            m = tn[1]\n",
    "            maxvol = tn[3]\n",
    "            break\n",
    "    \n",
    "##    print(\"m strategy first above 10 tone: \",m,maxvol)\n",
    "##    input()\n",
    "###HUMAN VOICE  ROUTINE\n",
    "    # if tonestype == \"human\":\n",
    "    # m = possible_tones[jmax][1] #this is max volume tone in the sample - good for HUMAN voice identification - not for instrument\n",
    "    # maxvol = possible_tones[jmax][3]\n",
    "\n",
    "    for elem in possible_tones:\n",
    "        print(elem)\n",
    "    return m\n",
    "#####FUNCTION WHICH RETURNS SINGLE MIDI FOR SINGLE TONE FILE - END\n",
    "\n",
    "single_pitch_to_MIDI(normalised_tone,rate)\n",
    "\n",
    "# ####FUNCTION FOR RETURNING WRITTEN TONE FROM MIDI VALUE\n",
    "# def findthetonetomidi(midivalue):\n",
    "#     tone=[['A0', 'A', 0, 27.5, 21, 0], ['Bb0', 'Bb', 0, 29.135, 22, 0], ['B0', 'B', 0, 30.868, 23, 0], ['C1', 'C', 1, 32.703, 24, 0], ['Cs1', 'Cs', 1, 34.648, 25, 0], ['D1', 'D', 1, 36.708, 26, 0], ['Eb1', 'Eb', 1, 38.891, 27, 0], ['E1', 'E', 1, 41.203, 28, 0], ['F1', 'F', 1, 43.654, 29, 0], ['Fs1', 'Fs', 1, 46.249, 30, 0], ['G1', 'G', 1, 48.999, 31, 0], ['Gs1', 'Gs', 1, 51.913, 32, 0], ['A1', 'A', 1, 55, 33, 0], ['Bb1', 'Bb', 1, 58.27, 34, 0], ['B1', 'B', 1, 61.735, 35, 0], ['C2', 'C', 2, 65.406, 36, 0], ['Cs2', 'Cs', 2, 69.296, 37, 0], ['D2', 'D', 2, 73.416, 38, 0], ['Eb2', 'Eb', 2, 77.782, 39, 0], ['E2', 'E', 2, 82.407, 40, 0], ['F2', 'F', 2, 87.307, 41, 0], ['Fs2', 'Fs', 2, 92.499, 42, 0], ['G2', 'G', 2, 97.999, 43, 0], ['Gs2', 'Gs', 2, 103.83, 44, 0], ['A2', 'A', 2, 110, 45, 0], ['Bb2', 'Bb', 2, 116.54, 46, 0], ['B2', 'B', 2, 123.47, 47, 0], ['C3', 'C', 3, 130.81, 48, 0], ['Cs3', 'Cs', 3, 138.59, 49, 0], ['D3', 'D', 3, 146.83, 50, 0], ['Eb3', 'Eb', 3, 155.56, 51, 0], ['E3', 'E', 3, 164.81, 52, 0], ['F3', 'F', 3, 174.61, 53, 0], ['Fs3', 'Fs', 3, 185, 54, 0], ['G3', 'G', 3, 196, 55, 0], ['Gs3', 'Gs', 3, 207.65, 56, 0], ['A3', 'A', 3, 220, 57, 0], ['Bb3', 'Bb', 3, 233.08, 58, 0], ['B3', 'B', 3, 246.94, 59, 0], ['C4', 'C', 4, 261.63, 60, 0], ['Cs4', 'Cs', 4, 277.18, 61, 0], ['D4', 'D', 4, 293.66, 62, 0], ['Eb4', 'Eb', 4, 311.13, 63, 0], ['E4', 'E', 4, 329.63, 64, 0], ['F4', 'F', 4, 349.23, 65, 0], ['Fs4', 'Fs', 4, 369.99, 66, 0], ['G4', 'G', 4, 392, 67, 0], ['Gs4', 'Gs', 4, 415.3, 68, 0], ['A4', 'A', 4, 440, 69, 0], ['Bb4', 'Bb', 4, 466.16, 70, 0], ['B4', 'B', 4, 493.88, 71, 0], ['C5', 'C', 5, 523.25, 72, 0], ['Cs5', 'Cs', 5, 554.37, 73, 0], ['D5', 'D', 5, 587.33, 74, 0], ['Eb5', 'Eb', 5, 622.25, 75, 0], ['E5', 'E', 5, 659.26, 76, 0], ['F5', 'F', 5, 698.46, 77, 0], ['Fs5', 'Fs', 5, 739.99, 78, 0], ['G5', 'G', 5, 783.99, 79, 0], ['Gs5', 'Gs', 5, 830.61, 80, 0], ['A5', 'A', 5, 880, 81, 0], ['Bb5', 'Bb', 5, 932.33, 82, 0], ['B5', 'B', 5, 987.77, 83, 0], ['C6', 'C', 6, 1046.5, 84, 0], ['Cs6', 'Cs', 6, 1108.73, 85, 0], ['D6', 'D', 6, 1174.66, 86, 0], ['Eb6', 'Eb', 6, 1244.51, 87, 0], ['E6', 'E', 6, 1318.51, 88, 0], ['F6', 'F', 6, 1396.91, 89, 0], ['Fs6', 'Fs', 6, 1479.98, 90, 0], ['G6', 'G', 6, 1567.98, 91, 0], ['Gs6', 'Gs', 6, 1661.22, 92, 0], ['A6', 'A', 6, 1760, 93, 0], ['Bb6', 'Bb', 6, 1864.66, 94, 0], ['B6', 'B', 6, 1975.53, 95, 0], ['C7', 'C', 7, 2093, 96, 0], ['Cs7', 'Cs', 7, 2217.46, 97, 0], ['D7', 'D', 7, 2349.32, 98, 0], ['Eb7', 'Eb', 7, 2489.02, 99, 0], ['E7', 'E', 7, 2637.02, 100, 0], ['F7', 'F', 7, 2793.83, 101, 0], ['Fs7', 'Fs', 7, 2959.96, 102, 0], ['G7', 'G', 7, 3135.96, 103, 0], ['Gs7', 'Gs', 7, 3322.44, 104, 0], ['A7', 'A', 7, 3520, 105, 0], ['Bb7', 'Bb', 7, 3729.31, 106, 0], ['B7', 'B', 7, 3951.07, 107, 0], ['C8', 'C', 8, 4186.01, 108, 0]]\n",
    "#     miditone=0\n",
    "#     for t in range(0,len(tone)):\n",
    "#             if tone[t][4] == midivalue:\n",
    "#                 miditone = tone[t][0]\n",
    "#                 break\n",
    "#     return(miditone)\n",
    "# ####FUNCTION FOR RETURNING TONE FROM MIDI VALUE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further inspection -- when I used human voice, the most powerful/ highest amplitude frequency was the frequency that corresponded to the right note, while with the piano I had to force the note down to the first note that had a high amplitude.\n",
    "\n",
    "Due to different sound envelopes, the piano has different and more powerful overtones/ harmonics compared to the human voice.\n",
    "\n",
    "Thus, now I have two methods -- one for piano, and one for human voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please wait till the next message. Libraries are loading now\")\n",
    "\n",
    "import scipy, matplotlib\n",
    "#https://realpython.com/python-scipy-fft/ the gude was from here\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import scipy.io\n",
    "from scipy.io.wavfile import write\n",
    "from midiutil import MIDIFile\n",
    "import math\n",
    "from scipy.fft import irfft\n",
    "from pygame import mixer\n",
    "from scipy.fft import rfft, rfftfreq #import Frourier Transformation library\n",
    "from basic_pitch.inference import predict\n",
    "from basic_pitch.inference import predict_and_save\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "import os\n",
    "import pathlib\n",
    "import tempfile\n",
    "import unittest\n",
    "import librosa\n",
    "import pretty_midi\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH, inference\n",
    "from basic_pitch.constants import ANNOTATIONS_N_SEMITONES\n",
    "\n",
    "#https://github.com/craffel/pretty-midi/blob/main/Tutorial.ipynb\n",
    "# For Python2.6 compatibility\n",
    "#from __future__ import print_function\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "# For plotting\n",
    "import mir_eval.display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "# For putting audio in the notebook\n",
    "import IPython.display\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "#https://www.programiz.com/python-programming/time#:~:text=In%20Python%2C%20the%20time(),00%20at%20UTC%20is%20epoch.&text=In%20the%20above%20example%2C%20we,and%20then%20printed%20the%20result.\n",
    "\n",
    "print(\"Libraries have been loaded\")\n",
    "\n",
    "\n",
    "##########################################record voice by laptop microphone\n",
    "chunk = 512#1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 2\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 5\n",
    "outwav = \"C:\\F\\AIVO Katie\\$$Wav to Midi\\OUTPUT.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "print(\"Recording for:  XXX seconds after you input number of seconds and press enter key. Default is: \",seconds,\"seconds\")\n",
    "seconds = int(input(\"Input number of seconds: \"))\n",
    "print(\"Recording for: \",seconds)\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for X seconds\n",
    "s0 = time.time()\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "    print(i,time.time()-s0)\n",
    "\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('Finished recording')\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(outwav, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "print(\"Finished Saving WAV FLLE to: \", filename)\n",
    "input()\n",
    "##########################################record voice by laptop microphone\n",
    "\n",
    "\n",
    "##https://github.com/spotify/basic-pitch\n",
    "#https://basicpitch.spotify.com/ = this is WRB SITE DROP IN\n",
    "##predict_and_save(\n",
    "##    <input-audio-path-list>,\n",
    "##    <output-directory>,\n",
    "##    <save-midi>,\n",
    "##    <sonify-midi>,\n",
    "##    <save-model-outputs>,\n",
    "##    <save-note-events>,\n",
    "##)\n",
    "##predict()\n",
    "##\n",
    "##Import basic-pitch into your own Python code and run the predict functions directly, providing an <input-audio-path> and returning the model's prediction results:\n",
    "##\n",
    "##from basic_pitch.inference import predict\n",
    "##from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "##\n",
    "##model_output, midi_data, note_activations = predict(<input-audio-path>)\n",
    "##<minimum-frequency> & <maximum-frequency> (floats) set the maximum and minimum allowed note frequency, in Hz, returned by the model. Pitch events with frequencies outside of this range will be excluded from the prediction results.\n",
    "##model_output is the raw model inference output\n",
    "##midi_data is the transcribed MIDI data derived from the model_output\n",
    "##note_events is a list of note events derived from the model_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outmidishortanalysis = inwav[:len(inwav)-4]+\"ShortAnalysis.mid\"\n",
    "outmidibeatanalysis = inwav[:len(inwav)-4]+\"BeatAnalysis.mid\"\n",
    "outmidilonganalysis = inwav[:len(inwav)-4]+\"LongAnalysis.mid\"\n",
    "outmidilonganalysisoriginal = inwav[:len(inwav)-4]+\"LongAnalysisOriginal.mid\"\n",
    "outmidibasicpitch = inwav[:len(inwav)-4]+\"Basicpitch.mid\"\n",
    "outmidibasicpitchoriginal = inwav[:len(inwav)-4]+\"Basicpitchoriginal.mid\" #as per Spotify script\n",
    "\n",
    "mixer.init()\n",
    "\n",
    "###THESE ARE MOST IMPORTNAT SWITCHES\n",
    "inwav = outwav # recorgin of voice\n",
    "BPM = 60 #BPM is very important and it is major input to the process. BPM = 60 works quite well with tone recognition;  BPM = 120 is used for most classical music\n",
    "tonestype = \"human\"\n",
    "#tonestype = \"instrument\"\n",
    "###THESE ARE MOST IMPORTNAT SWITCHES\n",
    "\n",
    "\n",
    "#####MIXER AND PLAYER FUNCTION DEFINED - BEGINING\n",
    "def playmusicfile(inwav):\n",
    "        #Load audio file\n",
    "    mixer.music.load(inwav)\n",
    "    print(\"music started playing for file called: \", inwav)\n",
    "    #Set preferred volume\n",
    "    mixer.music.set_volume(0.5)\n",
    "    #Play the music\n",
    "    mixer.music.play(-1) #-1 means infitinte loop\n",
    "    #Infinite loop\n",
    "    while True:\n",
    "        print(\"We are playing file: \",inwav)\n",
    "        print(\"Press 'p' to pause the music\")\n",
    "        print(\"Press 'r' to resume the music\")\n",
    "        print(\"Press 'e' to exit the program\")\n",
    "        #take user input\n",
    "        userInput = input(\" \")\n",
    "        if userInput == 'p':\n",
    "            # Pause the music\n",
    "            mixer.music.pause()\n",
    "            print(\"music is paused....\")\n",
    "        elif userInput == 'r':\n",
    "            #Resume the music\n",
    "            mixer.music.unpause()\n",
    "            print(\"music is resumed....\")\n",
    "        elif userInput == 'e':\n",
    "            # Stop the music playback\n",
    "            mixer.music.stop()\n",
    "            print(\"music is stopped....\")\n",
    "            break\n",
    "#####MIXER AND PLAYER FUNCTION DEFINED - END\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#####FUNCTION WHICH RETURNS SINGLE MIDI FOR SINGLE TONE VAW FILE - BEGINING\n",
    "def toneandmidiforsinglewavfile(normalized_tone_left_samples,samplerate,tonestype):\n",
    "    N=len(normalized_tone_left_samples)\n",
    "    yf = rfft(normalized_tone_left_samples)\n",
    "    xf = rfftfreq(N, 1 / samplerate)\n",
    "    k = min(len(xf),len(yf))\n",
    "    xf = xf[:k]\n",
    "    yf=yf[:k]\n",
    "    points_per_freq = len(xf) / (samplerate / 2) #this is number of x plotted points for 1 Herz of frequency\n",
    "    # Our target frequency is 4000 Hz for showing on the graph; Piano highest key is: 4186 Hz\n",
    "    k = int(points_per_freq * 4200) #maximum 4200 Hz\n",
    "    xf = xf[:k] #all frequencies above 4200 Hz is cut off\n",
    "    yf=yf[:k]\n",
    "    k0 = 0\n",
    "    A = 0\n",
    "    Amax = 0\n",
    "    tone=[['A0', 'A', 0, 27.5, 21, 0], ['Bb0', 'Bb', 0, 29.135, 22, 0], ['B0', 'B', 0, 30.868, 23, 0], ['C1', 'C', 1, 32.703, 24, 0], ['Cs1', 'Cs', 1, 34.648, 25, 0], ['D1', 'D', 1, 36.708, 26, 0], ['Eb1', 'Eb', 1, 38.891, 27, 0], ['E1', 'E', 1, 41.203, 28, 0], ['F1', 'F', 1, 43.654, 29, 0], ['Fs1', 'Fs', 1, 46.249, 30, 0], ['G1', 'G', 1, 48.999, 31, 0], ['Gs1', 'Gs', 1, 51.913, 32, 0], ['A1', 'A', 1, 55, 33, 0], ['Bb1', 'Bb', 1, 58.27, 34, 0], ['B1', 'B', 1, 61.735, 35, 0], ['C2', 'C', 2, 65.406, 36, 0], ['Cs2', 'Cs', 2, 69.296, 37, 0], ['D2', 'D', 2, 73.416, 38, 0], ['Eb2', 'Eb', 2, 77.782, 39, 0], ['E2', 'E', 2, 82.407, 40, 0], ['F2', 'F', 2, 87.307, 41, 0], ['Fs2', 'Fs', 2, 92.499, 42, 0], ['G2', 'G', 2, 97.999, 43, 0], ['Gs2', 'Gs', 2, 103.83, 44, 0], ['A2', 'A', 2, 110, 45, 0], ['Bb2', 'Bb', 2, 116.54, 46, 0], ['B2', 'B', 2, 123.47, 47, 0], ['C3', 'C', 3, 130.81, 48, 0], ['Cs3', 'Cs', 3, 138.59, 49, 0], ['D3', 'D', 3, 146.83, 50, 0], ['Eb3', 'Eb', 3, 155.56, 51, 0], ['E3', 'E', 3, 164.81, 52, 0], ['F3', 'F', 3, 174.61, 53, 0], ['Fs3', 'Fs', 3, 185, 54, 0], ['G3', 'G', 3, 196, 55, 0], ['Gs3', 'Gs', 3, 207.65, 56, 0], ['A3', 'A', 3, 220, 57, 0], ['Bb3', 'Bb', 3, 233.08, 58, 0], ['B3', 'B', 3, 246.94, 59, 0], ['C4', 'C', 4, 261.63, 60, 0], ['Cs4', 'Cs', 4, 277.18, 61, 0], ['D4', 'D', 4, 293.66, 62, 0], ['Eb4', 'Eb', 4, 311.13, 63, 0], ['E4', 'E', 4, 329.63, 64, 0], ['F4', 'F', 4, 349.23, 65, 0], ['Fs4', 'Fs', 4, 369.99, 66, 0], ['G4', 'G', 4, 392, 67, 0], ['Gs4', 'Gs', 4, 415.3, 68, 0], ['A4', 'A', 4, 440, 69, 0], ['Bb4', 'Bb', 4, 466.16, 70, 0], ['B4', 'B', 4, 493.88, 71, 0], ['C5', 'C', 5, 523.25, 72, 0], ['Cs5', 'Cs', 5, 554.37, 73, 0], ['D5', 'D', 5, 587.33, 74, 0], ['Eb5', 'Eb', 5, 622.25, 75, 0], ['E5', 'E', 5, 659.26, 76, 0], ['F5', 'F', 5, 698.46, 77, 0], ['Fs5', 'Fs', 5, 739.99, 78, 0], ['G5', 'G', 5, 783.99, 79, 0], ['Gs5', 'Gs', 5, 830.61, 80, 0], ['A5', 'A', 5, 880, 81, 0], ['Bb5', 'Bb', 5, 932.33, 82, 0], ['B5', 'B', 5, 987.77, 83, 0], ['C6', 'C', 6, 1046.5, 84, 0], ['Cs6', 'Cs', 6, 1108.73, 85, 0], ['D6', 'D', 6, 1174.66, 86, 0], ['Eb6', 'Eb', 6, 1244.51, 87, 0], ['E6', 'E', 6, 1318.51, 88, 0], ['F6', 'F', 6, 1396.91, 89, 0], ['Fs6', 'Fs', 6, 1479.98, 90, 0], ['G6', 'G', 6, 1567.98, 91, 0], ['Gs6', 'Gs', 6, 1661.22, 92, 0], ['A6', 'A', 6, 1760, 93, 0], ['Bb6', 'Bb', 6, 1864.66, 94, 0], ['B6', 'B', 6, 1975.53, 95, 0], ['C7', 'C', 7, 2093, 96, 0], ['Cs7', 'Cs', 7, 2217.46, 97, 0], ['D7', 'D', 7, 2349.32, 98, 0], ['Eb7', 'Eb', 7, 2489.02, 99, 0], ['E7', 'E', 7, 2637.02, 100, 0], ['F7', 'F', 7, 2793.83, 101, 0], ['Fs7', 'Fs', 7, 2959.96, 102, 0], ['G7', 'G', 7, 3135.96, 103, 0], ['Gs7', 'Gs', 7, 3322.44, 104, 0], ['A7', 'A', 7, 3520, 105, 0], ['Bb7', 'Bb', 7, 3729.31, 106, 0], ['B7', 'B', 7, 3951.07, 107, 0], ['C8', 'C', 8, 4186.01, 108, 0]]\n",
    "    #['A0', 'A', 0, 27.5, 21, 0] = one record of keyboard; Item[5] is Amplitude of Fourier transformation\n",
    "    kkey = [['A',1], ['Bb',1], ['B',1], ['C',1], ['Cs',1], ['D',1], ['Eb',1], ['E',1], ['F',1], ['Fs',1], ['G',1], ['Gs',1]]\n",
    "    maxoctave = 0 \n",
    "    t=len(tone)\n",
    "    jmax = 0\n",
    "    for j in range(0,t):\n",
    "        f = tone[j][3] #frequency of the tone in the table - I am looking for values only for the Tones of keyboard (not for all frequencies)\n",
    "        for i in range(k0,k-1):\n",
    "            #i = i + 1\n",
    "            f1 = xf[i]\n",
    "            f2 = xf[i+1]\n",
    "            if  ((f1 <= f) and (f < f2)):\n",
    "                A = abs(abs(yf[i+1]) - abs(yf[i]))/(f2-f1)+abs(yf[i])\n",
    "                if A > Amax:\n",
    "                    Amax = A\n",
    "                    jmax = j\n",
    "                tone[j][5] = A\n",
    "                k0 = k0+1\n",
    "                break    \n",
    "    p = len(tone)\n",
    "    q = len(kkey)\n",
    "    #r = len(octave)\n",
    "    for pp in range(0,t):\n",
    "        if Amax != 0:\n",
    "            tone[pp][5] = tone[pp][5]/Amax*100\n",
    "            if tone[pp][5] <=10: #to filter out smaller sounding tones - only 10 and more from 100 are allowed) - otherwise set to 1\n",
    "                tone[pp][5] = 1\n",
    "        else: tone[pp][5] = 1\n",
    "\n",
    "\n",
    "##    for t in tone:\n",
    "##        print(t)\n",
    "##    input()\n",
    "####\n",
    "##INSTRUMENT ROUTINE\n",
    "    for tn in tone:\n",
    "        if tn[5] > 1: #finds the first tone with volume above 10 - which is probably low cut out\n",
    "            maxko = tn[0]\n",
    "            m = tn[4]\n",
    "            maxvol = tn[5]\n",
    "            break\n",
    "    \n",
    "##    print(\"m strategy first above 10 tone: \",m,maxvol)\n",
    "##    input()\n",
    "###HUMAN VOICE  ROUTINE\n",
    "    if tonestype == \"human\":\n",
    "        m = tone[jmax][4] #this is max volume tone in the sample - good for HUMAN voice identification - not for instrument\n",
    "        maxvol = tone[jmax][5]\n",
    "##    print(\"m strategy max volume tone: \",m,maxvol)\n",
    "##    input()\n",
    "##    \n",
    "    \n",
    "           \n",
    "##    print(\"maxko: \",maxko) #tone for maximum\n",
    "##    print(m) #midi for maximum\n",
    "    return(m)\n",
    "#####FUNCTION WHICH RETURNS SINGLE MIDI FOR SINGLE TONE FILE - END\n",
    "\n",
    "####FUNCTION FOR RETURNING WRITTEN TONE FROM MIDI VALUE\n",
    "def findthetonetomidi(midivalue):\n",
    "    tone=[['A0', 'A', 0, 27.5, 21, 0], ['Bb0', 'Bb', 0, 29.135, 22, 0], ['B0', 'B', 0, 30.868, 23, 0], ['C1', 'C', 1, 32.703, 24, 0], ['Cs1', 'Cs', 1, 34.648, 25, 0], ['D1', 'D', 1, 36.708, 26, 0], ['Eb1', 'Eb', 1, 38.891, 27, 0], ['E1', 'E', 1, 41.203, 28, 0], ['F1', 'F', 1, 43.654, 29, 0], ['Fs1', 'Fs', 1, 46.249, 30, 0], ['G1', 'G', 1, 48.999, 31, 0], ['Gs1', 'Gs', 1, 51.913, 32, 0], ['A1', 'A', 1, 55, 33, 0], ['Bb1', 'Bb', 1, 58.27, 34, 0], ['B1', 'B', 1, 61.735, 35, 0], ['C2', 'C', 2, 65.406, 36, 0], ['Cs2', 'Cs', 2, 69.296, 37, 0], ['D2', 'D', 2, 73.416, 38, 0], ['Eb2', 'Eb', 2, 77.782, 39, 0], ['E2', 'E', 2, 82.407, 40, 0], ['F2', 'F', 2, 87.307, 41, 0], ['Fs2', 'Fs', 2, 92.499, 42, 0], ['G2', 'G', 2, 97.999, 43, 0], ['Gs2', 'Gs', 2, 103.83, 44, 0], ['A2', 'A', 2, 110, 45, 0], ['Bb2', 'Bb', 2, 116.54, 46, 0], ['B2', 'B', 2, 123.47, 47, 0], ['C3', 'C', 3, 130.81, 48, 0], ['Cs3', 'Cs', 3, 138.59, 49, 0], ['D3', 'D', 3, 146.83, 50, 0], ['Eb3', 'Eb', 3, 155.56, 51, 0], ['E3', 'E', 3, 164.81, 52, 0], ['F3', 'F', 3, 174.61, 53, 0], ['Fs3', 'Fs', 3, 185, 54, 0], ['G3', 'G', 3, 196, 55, 0], ['Gs3', 'Gs', 3, 207.65, 56, 0], ['A3', 'A', 3, 220, 57, 0], ['Bb3', 'Bb', 3, 233.08, 58, 0], ['B3', 'B', 3, 246.94, 59, 0], ['C4', 'C', 4, 261.63, 60, 0], ['Cs4', 'Cs', 4, 277.18, 61, 0], ['D4', 'D', 4, 293.66, 62, 0], ['Eb4', 'Eb', 4, 311.13, 63, 0], ['E4', 'E', 4, 329.63, 64, 0], ['F4', 'F', 4, 349.23, 65, 0], ['Fs4', 'Fs', 4, 369.99, 66, 0], ['G4', 'G', 4, 392, 67, 0], ['Gs4', 'Gs', 4, 415.3, 68, 0], ['A4', 'A', 4, 440, 69, 0], ['Bb4', 'Bb', 4, 466.16, 70, 0], ['B4', 'B', 4, 493.88, 71, 0], ['C5', 'C', 5, 523.25, 72, 0], ['Cs5', 'Cs', 5, 554.37, 73, 0], ['D5', 'D', 5, 587.33, 74, 0], ['Eb5', 'Eb', 5, 622.25, 75, 0], ['E5', 'E', 5, 659.26, 76, 0], ['F5', 'F', 5, 698.46, 77, 0], ['Fs5', 'Fs', 5, 739.99, 78, 0], ['G5', 'G', 5, 783.99, 79, 0], ['Gs5', 'Gs', 5, 830.61, 80, 0], ['A5', 'A', 5, 880, 81, 0], ['Bb5', 'Bb', 5, 932.33, 82, 0], ['B5', 'B', 5, 987.77, 83, 0], ['C6', 'C', 6, 1046.5, 84, 0], ['Cs6', 'Cs', 6, 1108.73, 85, 0], ['D6', 'D', 6, 1174.66, 86, 0], ['Eb6', 'Eb', 6, 1244.51, 87, 0], ['E6', 'E', 6, 1318.51, 88, 0], ['F6', 'F', 6, 1396.91, 89, 0], ['Fs6', 'Fs', 6, 1479.98, 90, 0], ['G6', 'G', 6, 1567.98, 91, 0], ['Gs6', 'Gs', 6, 1661.22, 92, 0], ['A6', 'A', 6, 1760, 93, 0], ['Bb6', 'Bb', 6, 1864.66, 94, 0], ['B6', 'B', 6, 1975.53, 95, 0], ['C7', 'C', 7, 2093, 96, 0], ['Cs7', 'Cs', 7, 2217.46, 97, 0], ['D7', 'D', 7, 2349.32, 98, 0], ['Eb7', 'Eb', 7, 2489.02, 99, 0], ['E7', 'E', 7, 2637.02, 100, 0], ['F7', 'F', 7, 2793.83, 101, 0], ['Fs7', 'Fs', 7, 2959.96, 102, 0], ['G7', 'G', 7, 3135.96, 103, 0], ['Gs7', 'Gs', 7, 3322.44, 104, 0], ['A7', 'A', 7, 3520, 105, 0], ['Bb7', 'Bb', 7, 3729.31, 106, 0], ['B7', 'B', 7, 3951.07, 107, 0], ['C8', 'C', 8, 4186.01, 108, 0]]\n",
    "    miditone=0\n",
    "    for t in range(0,len(tone)):\n",
    "            if tone[t][4] == midivalue:\n",
    "                miditone = tone[t][0]\n",
    "                break\n",
    "    return(miditone)\n",
    "####FUNCTION FOR RETURNING TONE FROM MIDI VALUE\n",
    "\n",
    "#Initial description of thw WAV file\n",
    "samplerate, data = wavfile.read(inwav)\n",
    "print(\"samplerate datapoints per second: \",samplerate)\n",
    "lengthofwavinseconds = data.shape[0] / samplerate #data.shape[0]is lenght of the wav file in seconds;\n",
    "lengthofwavindatapoints = data.shape[0]\n",
    "numberofchanels = data.ndim\n",
    "print(\"length of wav in data points: \",lengthofwavindatapoints)\n",
    "print(\"length of wav in seconds: \",lengthofwavinseconds)\n",
    "print(\"numberofchanels: \",numberofchanels)\n",
    "normalized_tone = np.int16((data[:]/data[:].max()) * 32767) # this is the tone definition normalizes to 32k bits = standard height for the tone to be identified#\n",
    "playmusicfile(inwav)\n",
    "plt.plot(normalized_tone)\n",
    "plt.xlabel(\"X axis in points\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.ylim([-32767, 32767])\n",
    "plt.show()\n",
    "#Normalized tone will be used for further analysis\n",
    "\n",
    "\n",
    "lenghofsampleinseconds = 60/BPM #int(data.shape[0]/numberofsamples) in Seconds; if sample has lenght of 0.25 seconds = 240BPM (60 x 4)\n",
    "print(\"BPM: \",BPM)\n",
    "lenghofsampleindatapoints = int(lenghofsampleinseconds*samplerate) #int(data.shape[0]/numberofsamples) in datapoints in waw\n",
    "print(\"lenghofsampleinseconds: \",lenghofsampleinseconds)\n",
    "print(\"lenghofsampleindatapoints: \",lenghofsampleindatapoints)\n",
    "##BPM\n",
    "\n",
    "\n",
    "####Make noise between two distinct tones down to zero\n",
    "#Important parameter is at what percentage of average sound or at what sound value  the sound should be cut off\n",
    "normalized_tone_left = [0]*lengthofwavindatapoints #the list of averages\n",
    "if numberofchanels == 1:\n",
    "    for i in range(0,lengthofwavindatapoints):\n",
    "        normalized_tone_left[i] = (normalized_tone[i])\n",
    "else:\n",
    "    for i in range(0,lengthofwavindatapoints):\n",
    "        normalized_tone_left[i] = (normalized_tone[i][0]) #[0] = only left channel\n",
    "        \n",
    "for i in range(0,lengthofwavindatapoints):\n",
    "    if abs(normalized_tone_left[i]) <1000: #filtering on 1000 out of 32000 - maybe can filter more\n",
    "        normalized_tone_left[i] = 0\n",
    "plt.plot(normalized_tone_left)\n",
    "plt.xlabel(\"X axis in points\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.ylim([-32767, 32767])\n",
    "plt.show()\n",
    "print(\"len(normalized_tone_left): \",len(normalized_tone_left))\n",
    "\n",
    "\n",
    "###########################################MAIN_FUNCTION_FOR_GIVEN_SAMPLE_INTERVAL_Whis_is_0.01secondwide##################################################\n",
    "def returnmidivalueforsamplefromdatapoint(data,s0,lenghofsampleindatapoints):\n",
    "    s1 = s0 + lenghofsampleindatapoints\n",
    "    #data1s = data[s0:s1,0] #0 means left channel of wav\n",
    "    data1s = data[s0:s1] #this is from already left channel of normalized wav\n",
    "    normalized_tone = data1s\n",
    "#    if data1s[:].max() > 0:\n",
    "#        normalized_tone = np.int16((data1s[:] / data1s[:].max()) * 32767) # this is the tone definition normalizes to 32k bits = standard height for the tone to be identified\n",
    "##    plt.plot(s0,s1,normalized_tone)\n",
    "##    plt.xlabel(\"X axis in points\")\n",
    "##    plt.ylabel(\"Amplitude\")\n",
    "##    plt.ylim([-32767, 32767])\n",
    "##    plt.show()\n",
    "    N = s1 - s0 #N -s niumber of points on X Axis (frequencies); length is the length of the Waw file in seconds\n",
    "    yf = rfft(normalized_tone) #Rapid Fourier transformation on Normalized Tone - returns Aplitude for each frequency\n",
    "    xf = rfftfreq(N, 1 / samplerate)\n",
    "    # Return the Discrete Fourier Transform sample frequencies (for usage with rfft, irfft).\n",
    "    #The returned float array f contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start).\n",
    "    #For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second.\n",
    "    #Sample spacing (inverse of the sampling rate). Defaults to 1.\n",
    "    #print(\"Plot of FFT Frequency distribution - this meanst FFT worked\")\n",
    "    k = min(len(xf),len(yf))\n",
    "##    print(\"len(xf),len(yf),k:\",len(xf),len(yf),k)\n",
    "##    input()\n",
    "    xf = xf[:k]\n",
    "    yf=yf[:k]\n",
    "##    plt.plot(xf, np.abs(yf))\n",
    "##    plt.xlabel(\"Frequencies in the Wave Sample in Hz\")\n",
    "##    plt.ylabel(\"FFT Amplitude of given Frequency\")\n",
    "##    plt.xlim([0,4000]) #plot frequency from 0 to 4000 Hz\n",
    "##    plt.show()\n",
    "    # The maximum detectable frequency is half the sample rate (44100 sample rate can determine frequency up to 22kHz (ie. maximum hearing range)\n",
    "\n",
    "    fftpoint1 = 0\n",
    "    fftyvalue1 =0\n",
    "    fftpoint2 = 0\n",
    "    fftyvalue2 =0\n",
    "    fftpoint3 = 0\n",
    "    fftyvalue3 =0\n",
    "    fftpoint4 = 0\n",
    "    fftyvalue4 =0\n",
    "    fftpoint5 = 0\n",
    "    fftyvalue5 =0\n",
    "    fftpoint6 = 0\n",
    "    fftyvalue6 =0\n",
    "    \n",
    "    for j in range(0,k):\n",
    "        if yf[j] > fftyvalue1:\n",
    "            fftyvalue1 = yf[j]\n",
    "            fftpoint1 = j\n",
    "        elif yf[j] > fftyvalue2:\n",
    "                fftyvalue2 = yf[j]\n",
    "                fftpoint2 = j\n",
    "        elif yf[j] > fftyvalue3:\n",
    "                fftyvalue3 = yf[j]\n",
    "                fftpoint3 = j\n",
    "        elif yf[j] > fftyvalue4:\n",
    "                fftyvalue4 = yf[j]\n",
    "                fftpoint4 = j\n",
    "        elif yf[j] > fftyvalue5:\n",
    "                fftyvalue5 = yf[j]\n",
    "                fftpoint5 = j\n",
    "        elif yf[j] > fftyvalue6:\n",
    "                fftyvalue6 = yf[j]\n",
    "                fftpoint6 = j\n",
    "                \n",
    "                \n",
    "#    print(\"maxfftpoint:\", maxfftpoint) #frequency point with maximum\n",
    "    fftfrequency1 = xf[fftpoint1] #from frequency distribution\n",
    "    fftfrequency2 = xf[fftpoint2] #from frequency distribution\n",
    "    fftfrequency3 = xf[fftpoint3] #from frequency distribution\n",
    "    fftfrequency4 = xf[fftpoint4] #from frequency distribution\n",
    "    fftfrequency5 = xf[fftpoint5] #from frequency distribution\n",
    "    fftfrequency6 = xf[fftpoint6] #from frequency distribution\n",
    "\n",
    "    \n",
    "    #print(\"maxfftfrequency: \", maxfftfrequency)\n",
    "    #input()\n",
    "    ##m  =  12*log2(fm/440 Hz) + 69\n",
    "    midiformaxfftfrequency1 = 0 #default if there is no noise in the tone\n",
    "    midiformaxfftfrequency2 = 0 #default if there is no noise in the tone\n",
    "    midiformaxfftfrequency3 = 0 #default if there is no noise in the tone\n",
    "    midiformaxfftfrequency4 = 0 #default if there is no noise in the tone\n",
    "    midiformaxfftfrequency5 = 0 #default if there is no noise in the tone\n",
    "    midiformaxfftfrequency6 = 0 #default if there is no noise in the tone\n",
    "    \n",
    "    if fftfrequency1 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency1 =  int(round((12*math.log2(fftfrequency1/440) + 69),0)) #m has to be integer\n",
    "    if fftfrequency2 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency2 =  int(round((12*math.log2(fftfrequency2/440) + 69),0)) #m has to be integer\n",
    "    if fftfrequency3 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency3 =  int(round((12*math.log2(fftfrequency3/440) + 69),0)) #m has to be integer\n",
    "    if fftfrequency4 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency4 =  int(round((12*math.log2(fftfrequency4/440) + 69),0)) #m has to be integer\n",
    "    if fftfrequency5 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency5 =  int(round((12*math.log2(fftfrequency4/440) + 69),0)) #m has to be integer\n",
    "    if fftfrequency6 > 10: #minimum must be at leats 10 Hz\n",
    "        midiformaxfftfrequency6 =  int(round((12*math.log2(fftfrequency4/440) + 69),0)) #m has to be integer\n",
    "        \n",
    "    #print(\"maxfftfrequency: \", maxfftfrequency)\n",
    "    #print(\"midiformaxfftfrequency: \",midiformaxfftfrequency)\n",
    "    return(midiformaxfftfrequency1,midiformaxfftfrequency2,midiformaxfftfrequency3,midiformaxfftfrequency4,midiformaxfftfrequency5,midiformaxfftfrequency6)\n",
    "###########################################MAIN_FUNCTION_FOR_GIVEN_SAMPLE_INTERVAL##################################################\n",
    "\n",
    "########METHOD 4  = MOVING AREA ANALYSIS BASED ON LOOKING FOR CONSISTENT FREQUENCY OF THE NOTE OVER EXTENDED INTERVALS OF THE SOUND RECORDING\n",
    "print(\"METHOD 4: Entering analysis section of the software. This take a bit. No need to press any keys. Thank you.\")\n",
    "points_to_run_analysis = int(samplerate/100) #if 100 - each point will represent 0.01 seconds  = 100 points per second\n",
    "midisound0 = [] #= this is the output file for midi sounds\n",
    "midisound1 = []\n",
    "midisound2 = []\n",
    "midisound3 = []\n",
    "midisound4 = []\n",
    "midisound5 = []\n",
    "\n",
    "\n",
    "for s0 in range(0,lengthofwavindatapoints,points_to_run_analysis):\n",
    "    m = returnmidivalueforsamplefromdatapoint(normalized_tone_left,s0,lenghofsampleindatapoints) #normalized _tone_left is left channel of Wav file\n",
    "    midisound0.append(m)\n",
    "#minimum for 1-6 maximum points in FFT\n",
    "for i in range(0,len(midisound0)):\n",
    "    p = 1000\n",
    "    for j in range(0,6):\n",
    "        if midisound0[i][j]<p:\n",
    "            p = midisound0[i][j]\n",
    "    midisound1.append(p)\n",
    "#selection of minimum MIDI in the interval -15 and + 15 codes before gives point (each code is 0.01 seconds = width of selection is 0.30 seconds)\n",
    "w = 15 #width of minimum MIDI seeking\n",
    "p=1000\n",
    "for i in range(0,w):\n",
    "    p = min(midisound1[0:w])\n",
    "    midisound2.append(p)\n",
    "for i in range(w,len(midisound1)-w):\n",
    "    p = min(midisound1[(i-w):(i+w)])\n",
    "    midisound2.append(p)\n",
    "for i in range(len(midisound1)-w,len(midisound1)):\n",
    "    p = min(midisound1[len(midisound1)-w:len(midisound1)])\n",
    "    midisound2.append(p)\n",
    "\n",
    "j=0\n",
    "midisound3.append([midisound2[0],0.01]) # integrating the midi tones to beat files; each point is 0.01 second\n",
    "for i in range(1,len(midisound2)):\n",
    "    t = midisound2[i]\n",
    "    if t == midisound3[j][0]:\n",
    "        midisound3[j][1] = midisound3[j][1] + 0.01\n",
    "    else:\n",
    "        midisound3.append([midisound2[i],0.01])\n",
    "        j=j+1\n",
    "\n",
    "k = len(midisound3)\n",
    "BPM3Original = 60/(lengthofwavinseconds/k)\n",
    "midisound3original = []\n",
    "i=-1\n",
    "for m in midisound3:\n",
    "    if tonestype == \"instrument\":\n",
    "        cutout = 0.2\n",
    "    else: #if  tonestype == \"human\":\n",
    "        cutout = 0.1\n",
    "    if m[0]>0 and m[1]>cutout: # longer than 0.2 seconds = 300 BPM for instrument and 0.1s for human voice\n",
    "        midisound3original.append([findthetonetomidi(m[0]),m[0],m[1],BPM3Original,100]) #100 is volume\n",
    "        i = i+1\n",
    "    else:\n",
    "##        print(\"midisound3original[i][2]: \",i,midisound3original[i-1][2])\n",
    "##        input()\n",
    "##        print(\"midisound3original[i][2]: \",i,midisound3original[i][2])\n",
    "##        input()\n",
    "        if i > 0:\n",
    "            midisound3original[i][2] = midisound3original[i][2] + m[1] #if note is too short = add that time to the previous note which works\n",
    "        \n",
    "\n",
    "print(\"METHOD 4 = MIDI OUTPUT USING Movings averages approach ORIGINAL. Average BPM is: \",BPM3Original)\n",
    "for m in midisound3original:\n",
    "    print(m)\n",
    "input()\n",
    "\n",
    "\n",
    "for i in range (0,len(midisound3)):\n",
    "    durationofthetone = midisound3[i][1]\n",
    "    m = midisound3[i][0]\n",
    "    if (durationofthetone <=(1.5*(60/BPM))) and (durationofthetone >=(0.35*(60/BPM))) and (m> 20): #1.5 or 0.35 are important factors for note duration; M = 20 is minimum midi tone\n",
    "        durationofthetone = 60/BPM # force 1 beat time\n",
    "        midisound4.append([findthetonetomidi(m),m,durationofthetone,BPM,100])\n",
    "\n",
    "print(\"METHOD 4 = MIDI OUTPUT USING Movings averages approach - BPM Forced to BPM: \",BPM)\n",
    "for i in range(0,len(  midisound4)):\n",
    "    print(midisound4[i])\n",
    "\n",
    "input\n",
    "########END OF METHOD 4  = MOVING AREA ANALYSIS BASED ON LOOKING FOR CONSISTENT FREQUENCY OF THE NOTE OVER EXTENDED INTERVALS OF THE SOUND RECORDING\n",
    "print(\"####END OF ANALYTICAL APPROACHES\")\n",
    "\n",
    "\n",
    "##input()\n",
    "##print(\"Result of gaps one between tones analysis:\", msingle[:][1]) #basdd pon quiet period between sounds\n",
    "##print(\"Result of Constant Beat sequence analysis:\", msinglebybeat[:][1]) # this is the scale to be played as the resut using Beat division procedure\n",
    "##print(\"Result of moving averages  analysis:      \", midisound4[:][1]) # this is the scale to be played as the resut using complex procedure\n",
    "##print(\"Result of Spotify Basic Pitch abalysis:   \", midispotify2[:][1]) # this is the scale to be played as the resut using complex procedure\n",
    "##input()\n",
    "\n",
    "\n",
    "def midisoundlinsttonmidifile(degrees, BPM,outmidi):\n",
    "    #degrees  = [60, 62, 64, 65, 67, 69, 71, 72] # MIDI note number\n",
    "    #Cello instrument has program number 42\n",
    "    #https://midiutil.readthedocs.io/en/1.0.1/common.html\n",
    "\n",
    "##    track   = 0\n",
    "##    channel = 0\n",
    "##    time    = len(degrees)# add beats into the composition\n",
    "##    program = 42 # A Cello\n",
    "##    MyMIDI.addProgramChange(track, channel, time, program)\n",
    "\n",
    "#Open Midi file\n",
    "    MyMIDI = MIDIFile(1) # One track, defaults to format 1 (tempo track  automatically created)\n",
    "#First define the Track of Midi - we are using only one Track\n",
    "    track    = 0\n",
    "    time     = 0   # In beats\n",
    "    tempo    = BPM  # In BPM\n",
    "    MyMIDI.addTempo(track,time, tempo)\n",
    "\n",
    "    channel  = 0\n",
    "##    duration = 1   # In beats - this \n",
    "##    volume   = 127 # 0-127, as per the MIDI standard - Volume can be called Velocity\n",
    "    #pitch is MIDI channel pitch = Frequency of the Note\n",
    "    \n",
    "    for note in degrees:\n",
    "#       print(note)\n",
    "#       input()\n",
    "        pitch = note[1]\n",
    "        duration = note[2] #in seconds\n",
    "        duration = duration/(60/BPM) # in Beats\n",
    "        volume = note[4]\n",
    "        MyMIDI.addNote(track, channel, pitch, time, duration, volume)\n",
    "        time = time + duration #before it was 1\n",
    "    with open(outmidi, \"wb\") as output_file:\n",
    "        MyMIDI.writeFile(output_file)\n",
    "    #https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "msingle1=[]\n",
    "midisound41=[]\n",
    "midisound3original1 = []\n",
    "msinglebybeat1=[]\n",
    "midispotify21=[]\n",
    "midispotifyoriginal1=[]\n",
    "\n",
    "\n",
    "for m in msingle:\n",
    "    msingle1.append(m[1])\n",
    "for i in range(0,len(msinglebybeat)):\n",
    "    msinglebybeat1.append(msinglebybeat[i][1])\n",
    "for i in range(0,len(midisound4)):\n",
    "    midisound41.append(midisound4[i][1])\n",
    "for i in range(0,len(midisound3original)):\n",
    "    midisound3original1.append(midisound3original[i][1])\n",
    "for i in range(0,len(midispotify2)):\n",
    "    midispotify21.append(midispotify2[i][1])\n",
    "for i in range(0,len(midispotifyoriginal)):\n",
    "    midispotifyoriginal1.append(midispotifyoriginal[i][1])\n",
    "    \n",
    "print(\"MIDI for Short Sound Analysis: \",BPM,msingle1)\n",
    "print(\"MIDI for Beat Analysis:        \",BPM,msinglebybeat1)\n",
    "print(\"MIDI for Long Sound Analysis:  \",BPM,midisound41)\n",
    "print(\"MIDI for Long Sound Analysis:  \",BPM3Original,midisound3original1)\n",
    "print(\"MIDI for Spotify Basic Pitch:  \",BPM,midispotify21)\n",
    "print(\"MIDI for Spotify ORIGINAL:  \",BPMoriginal,midispotifyoriginal1)\n",
    "\n",
    "input()\n",
    "\n",
    "       \n",
    "midisoundlinsttonmidifile(msingle, BPM,outmidishortanalysis)\n",
    "midisoundlinsttonmidifile(msinglebybeat, BPM,outmidibeatanalysis)\n",
    "midisoundlinsttonmidifile(midisound4, BPM,outmidilonganalysis)\n",
    "midisoundlinsttonmidifile(midisound3original, BPM3Original,outmidilonganalysisoriginal)\n",
    "midisoundlinsttonmidifile(midispotify2, BPM,outmidibasicpitch)\n",
    "midisoundlinsttonmidifile(midispotifyoriginal, BPMoriginal,outmidibasicpitchoriginal)\n",
    "input()\n",
    "\n",
    "def printmidifile(outmidishortanalysis, samplerate):\n",
    "    #https://librosa.org/doc/main/auto_examples/plot_display.html#sphx-glr-auto-examples-plot-display-py\n",
    "    #librosa.display.specshow(data, *, x_coords=None, y_coords=None, x_axis=None, y_axis=None, sr=22050, hop_length=512, n_fft=None, win_length=None, fmin=None, fmax=None, tuning=0.0, bins_per_octave=12, key='C:maj', Sa=None, mela=None, thaat=None, auto_aspect=True, htk=False, unicode=True, intervals=None, unison=None, ax=None, **kwargs)\n",
    "    midi_data = pretty_midi.PrettyMIDI(outmidishortanalysis)\n",
    "    piano_roll = midi_data.get_piano_roll(times=midi_data.get_beats())\n",
    "    plt.figure()\n",
    "    librosa.display.specshow(piano_roll, sr=samplerate, x_axis='time', y_axis='cqt_note', fmin=100,fmax = 440)\n",
    "    #librosa.display.specshow(piano_roll, sr=samplerate, x_axis='time', y_axis='log', fmin=100)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "playmusicfile(inwav) #origonal file\n",
    "\n",
    "playmusicfile(outmidishortanalysis)\n",
    "printmidifile(outmidishortanalysis, samplerate)\n",
    "\n",
    "playmusicfile(outmidibeatanalysis)\n",
    "printmidifile(outmidibeatanalysis, samplerate)\n",
    "\n",
    "playmusicfile(outmidilonganalysis)\n",
    "printmidifile(outmidilonganalysis, samplerate)\n",
    "\n",
    "playmusicfile(outmidilonganalysisoriginal)\n",
    "printmidifile(outmidilonganalysisoriginal, samplerate)\n",
    "\n",
    "playmusicfile(outmidibasicpitch)\n",
    "printmidifile(outmidibasicpitch, samplerate)\n",
    "\n",
    "playmusicfile(outmidibasicpitchoriginal)\n",
    "printmidifile(outmidibasicpitchoriginal, samplerate)\n",
    "\n",
    "playmusicfile(inwav)\n",
    "\n",
    "print(\"END\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
